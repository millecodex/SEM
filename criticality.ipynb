{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import subprocess\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# using the csv file of CRITICALITY_SCORE and searching for \n",
    "# repos from 200_repos; this excludes new/current projects\n",
    "# download: https://storage.cloud.google.com/ossf-criticality-score\n",
    "# UDPATE: looks like a monthly run is published here (wish I had of known!)\n",
    "#-------------------------------------------------\n",
    "\n",
    "# Read '200_repos.csv' into DataFrame df\n",
    "#\n",
    "# NaN is assigned to empty cells\n",
    "df = pd.read_csv('200_repos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset dataframes for testing\n",
    "# use .copy() as slicing will not allow for assignment\n",
    "df10 = df.iloc[:10].copy()\n",
    "df33 = df.iloc[:33].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................66 criticality scores found and updated\n"
     ]
    }
   ],
   "source": [
    "dfs = df[['CMC_id', 'source_code', 'forge']].copy()\n",
    "dfc = pd.read_csv('project_criticality_all.csv')\n",
    "num = 0\n",
    "for row in dfs.itertuples():\n",
    "    # only search if github\n",
    "    if row.forge == 'github':\n",
    "        # only search for strings; floats (NaN) are skipped\n",
    "        if isinstance(row.source_code, str):\n",
    "            url = str(row.source_code)\n",
    "            # loop through df2 (criticality) looking for source code url\n",
    "            for row2 in dfc.itertuples():\n",
    "                if url == row2.url:\n",
    "                    dfs.at[row.Index, 'criticality'] = row2.criticality_score\n",
    "                    num += 1\n",
    "                    break\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()\n",
    "print(str(num), 'criticality scores found and updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update MERGED sheet with new data\n",
    "# 'CMC_id' is the key, drop 'repo', and 'forge' before the merge\n",
    "# to prevent duplicate columns\n",
    "dfs.drop(columns = ['source_code', 'forge'], inplace = True)\n",
    "dfm = pd.merge(df,dfs,on = ['CMC_id'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out new data\n",
    "dfs.to_csv('200_crit.csv', encoding='utf-8', index = 0)\n",
    "dfm.to_csv('200_merged.csv', encoding='utf-8', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# directly call CRITICALITY_SCORE\n",
    "# require github token and command line access\n",
    "#-------------------------------------------------\n",
    "#\n",
    "# >> repo: https://github.com/ossf/criticality_score\n",
    "# 0. make sure github access token is exported to PATH (see methodology notes)\n",
    "# 1. install: pip3 install criticality-score\n",
    "# 2. check PATH: WARNING: The script criticality_score is installed in '/home/user/.local/bin' which is not on PATH.\n",
    "# >> export PATH=\"/home/user/.local/bin:$PATH\"\n",
    "# 3. get 'GITHUB_AUTH_TOKEN' and export path on command line or set env variable in jupyter\n",
    "# \n",
    "# Set the environment variable 'GITHUB_AUTH_TOKEN'\n",
    "# (this is a short-cut; in the future look into pycrosskit)\n",
    "# >key = 'GITHUB_AUTH_TOKEN'\n",
    "# >os.environ[key] = 'secret'\n",
    "#\n",
    "# read out the value\n",
    "# >value = os.getenv(key)\n",
    "# >print(\"Value of 'GITHUB_AUTH_TOKEN' environment variable :\", value) \n",
    "#\n",
    "# 4. run: criticality_score --repo https://github.com/bitcoin/bitcoin\n",
    "#\n",
    "'''     \n",
    "['name: bitcoin',\n",
    " 'url: https://github.com/bitcoin/bitcoin',\n",
    " 'language: C++',\n",
    " 'created_since: 142',\n",
    " 'updated_since: 0',\n",
    " 'contributor_count: 961',\n",
    " 'org_count: 4',\n",
    " 'commit_frequency: 54.8',\n",
    " 'recent_releases_count: 3',\n",
    " 'updated_issues_count: 1920',\n",
    " 'closed_issues_count: 1467',\n",
    " 'comment_frequency: 2.7',\n",
    " 'dependents_count: 348588',\n",
    " 'criticality_score: 0.86651']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read '200_repos.csv' into DataFrame df\n",
    "df = pd.read_csv('200_repos.csv')\n",
    "# keep 'source_code' location and 'forge'\n",
    "df_in = df[['source_code', 'forge']].copy()\n",
    "# subset dataframes for testing\n",
    "#df_in = df_in.iloc[96:101].copy()\n",
    "#df33 = dfs.iloc[:33].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\n",
      " 5 total projects evaluated\n",
      " 1 criticality scores updated\n",
      " 4 repos private or missing\n",
      " Total time elapsed: 0.1 minutes\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# dfParse builds a dataFrame using bash output\n",
    "#  @output the command line output from calling criticality_score\n",
    "#  @firstTime boolean to initialize the dataframe the first loop call\n",
    "#  @dataframe the dataframe to be updated and returned\n",
    "# ------------------------------------------------\n",
    "def dfParse(output, firstUpdate, dataframe):\n",
    "    jout = json.dumps(output)    #jout is a str\n",
    "    out_dict = json.loads(jout)   #out_dict is a list\n",
    "    \n",
    "    # catch a possible traceback\n",
    "    if 'Traceback' in out_dict[0]:\n",
    "        print('found traceback')\n",
    "        return dataframe\n",
    "    \n",
    "    # prepare the dataFrame, initialize with column headers the same\n",
    "    # as the criticality_score output\n",
    "    df = pd.DataFrame(out_dict)\n",
    "    df.rename(columns = {0:'metric'}, inplace = True)\n",
    "    df[['metric','value']] = df.metric.str.split(expand = True)\n",
    "    df = df.transpose(copy = True)\n",
    "\n",
    "    # remove index column (with labels 'metric' & 'value')\n",
    "    # and reset the index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # rename columns according to first row; then drop the row\n",
    "    df = df.rename(columns = df.iloc[0]).drop(df.index[0])\n",
    "\n",
    "    if firstUpdate:\n",
    "        dataframe = df.copy()\n",
    "    else:\n",
    "        # append row[1] to df\n",
    "        dataframe = dataframe.append(df, ignore_index = True)   \n",
    "        \n",
    "    return dataframe\n",
    "\n",
    "# ------------------------------------------------\n",
    "# variables\n",
    "# ------------------------------------------------\n",
    "start = time.time()\n",
    "total = 0\n",
    "updated = 0\n",
    "firstUpdate = True\n",
    "df_out = pd.DataFrame\n",
    "# ------------------------------------------------\n",
    "# main loop requires dataFrame: 'df_in'\n",
    "#                     returns: 'df_out'\n",
    "# df_out does not have CMC_id and some will be missed;\n",
    "# should be able to merge back on 'url:'='source_code'\n",
    "# ------------------------------------------------\n",
    "# This takes a while, criticality_score has a built-in\n",
    "# rate limiter for handling github API limit.\n",
    "# Sample Output:\n",
    "#\n",
    "#\n",
    "#\n",
    "# ------------------------------------------------\n",
    "for row in df_in.itertuples():\n",
    "    # proceed if github and source_code is a string and not private\n",
    "    if (row.forge == 'github') and isinstance(row.source_code, str) and (row.source_code != 'private'):\n",
    "        cmd = 'criticality_score --repo ' + row.source_code\n",
    "        output = !{cmd}\n",
    "        # if first element is ['name':'bitcoin'], output is as expected, can parse\n",
    "        if 'name' in output[0]: \n",
    "            #firstUpdate = True\n",
    "            #if num > 0: firstTime = False\n",
    "            df_out = dfParse(output, firstUpdate, df_out)\n",
    "            firstUpdate = False\n",
    "            updated += 1\n",
    "    total += 1\n",
    "    sys.stdout.write(\".\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# log some output with a timer\n",
    "print('\\n',str(df_in.shape[0]), 'total projects evaluated\\n', \n",
    "      str(updated), 'criticality scores updated\\n', \n",
    "      str(total - updated), 'repos private or missing\\n', \n",
    "      'Total time elapsed:', round((time.time() - start)/60, 1), 'minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out new data\n",
    "#df_in.to_csv('crit_output_all.csv', encoding='utf-8', index = 0)\n",
    "#dft = df_in[['url:','criticality_score:']].copy()\n",
    "#dft.to_csv('200_crit.csv', encoding='utf-8', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
