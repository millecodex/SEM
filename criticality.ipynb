{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys,time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read '200_repos.csv' into DataFrame df\n",
    "#\n",
    "# NaN is assigned to empty cells\n",
    "df = pd.read_csv('200_repos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset dataframes for testing\n",
    "# use .copy() as slicing will not allow for assignment\n",
    "df10 = df.iloc[:10].copy()\n",
    "df33 = df.iloc[:33].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................................................................................................................................62 criticality scores found and updated\n"
     ]
    }
   ],
   "source": [
    "dfs = df[['CMC_id', 'source_code', 'forge']].copy()\n",
    "dfc = pd.read_csv('project_criticality_all.csv')\n",
    "num = 0\n",
    "for row in dfs.itertuples():\n",
    "    # only search if github\n",
    "    if row.forge == 'github':\n",
    "        # only search for strings; floats (NaN) are skipped\n",
    "        if isinstance(row.source_code, str):\n",
    "            url = str(row.source_code)\n",
    "            # loop through df2 (criticality) looking for source code url\n",
    "            for row2 in dfc.itertuples():\n",
    "                if url == row2.url:\n",
    "                    dfs.at[row.Index, 'criticality'] = row2.criticality_score\n",
    "                    num += 1\n",
    "                    break\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()\n",
    "print(str(num), 'criticality scores found and updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update MERGED sheet with new data\n",
    "# 'CMC_id' is the key, drop 'repo', and 'forge' before the merge\n",
    "# to prevent duplicate columns\n",
    "dfs.drop(columns = ['source_code', 'forge'], inplace = True)\n",
    "dfm = pd.merge(df,dfs,on = ['CMC_id'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out new data\n",
    "dfs.to_csv('200_crit.csv', encoding='utf-8', index = 0)\n",
    "dfm.to_csv('200_merged.csv', encoding='utf-8', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
