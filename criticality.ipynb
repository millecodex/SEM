{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--------------------------------------------------------------\n",
    "# #-- S E A R C H   C R I T I C A L I T Y   S P R E A D S H E E T\n",
    "# #--------------------------------------------------------------\n",
    "# # using the csv file of CRITICALITY_SCORE and searching for \n",
    "# # repos from 200_repos; this excludes new/current projects\n",
    "# # download: https://storage.cloud.google.com/ossf-criticality-score\n",
    "# # UDPATE: looks like a monthly run is published here (wish I had of known!)\n",
    "# #--------------------------------------------------------------\n",
    "# # Read '200_repos.csv' into DataFrame df\n",
    "# #\n",
    "# # NaN is assigned to empty cells\n",
    "# df = pd.read_csv('200_repos.csv')\n",
    "# dfs = df[['CMC_id', 'source_code', 'forge']].copy()\n",
    "# dfc = pd.read_csv('project_criticality_all.csv')\n",
    "# num = 0\n",
    "# for row in dfs.itertuples():\n",
    "#     # only search if github\n",
    "#     if row.forge == 'github':\n",
    "#         # only search for strings; floats (NaN) are skipped\n",
    "#         if isinstance(row.source_code, str):\n",
    "#             url = str(row.source_code)\n",
    "#             # loop through df2 (criticality) looking for source code url\n",
    "#             for row2 in dfc.itertuples():\n",
    "#                 if url == row2.url:\n",
    "#                     dfs.at[row.Index, 'criticality'] = row2.criticality_score\n",
    "#                     num += 1\n",
    "#                     break\n",
    "#             sys.stdout.write(\".\")\n",
    "#             sys.stdout.flush()\n",
    "# print(str(num), 'criticality scores found and updated')\n",
    "\n",
    "# # update MERGED sheet with new data\n",
    "# # 'CMC_id' is the key, drop 'repo', and 'forge' before the merge\n",
    "# # to prevent duplicate columns\n",
    "# dfs.drop(columns = ['source_code', 'forge'], inplace = True)\n",
    "# dfm = pd.merge(df,dfs,on = ['CMC_id'], how = 'outer')\n",
    "\n",
    "# # write out new data\n",
    "# dfs.to_csv('200_crit.csv', encoding='utf-8', index = 0)\n",
    "# dfm.to_csv('200_merged.csv', encoding='utf-8', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# -- C A L L   C R I T I C A L I T Y _ S C O R E--\n",
    "# require github token and command line access----\n",
    "#-------------------------------------------------\n",
    "#\n",
    "# Input:\n",
    "# 'cmc_repos_forge.csv' from prepare_repos.ipynb\n",
    "#\n",
    "# Outputs:\n",
    "# 'crit_output_all.csv' contains all the info; see sample output below\n",
    "# 'crit_only.csv' contains two columns: 'url:','criticality_score:'\n",
    "#\n",
    "# >> repo: https://github.com/ossf/criticality_score\n",
    "# 0. make sure github access token is exported to PATH (see methodology notes)\n",
    "# 1. install: pip3 install criticality-score\n",
    "# 2. check PATH: WARNING: The script criticality_score is installed in '/home/user/.local/bin' which is not on PATH.\n",
    "# >> export PATH=\"/home/user/.local/bin:$PATH\"\n",
    "# 3. get 'GITHUB_AUTH_TOKEN' and export path on command line or set env variable in jupyter\n",
    "# \n",
    "# Set the environment variable 'GITHUB_AUTH_TOKEN' from Jupyter\n",
    "# (this is a short-cut; in the future look into pycrosskit)\n",
    "# >key = 'GITHUB_AUTH_TOKEN'\n",
    "# >os.environ[key] = 'secret'\n",
    "#\n",
    "# read out the value\n",
    "# >value = os.getenv(key)\n",
    "# >print(\"Value of 'GITHUB_AUTH_TOKEN' environment variable :\", value) \n",
    "#\n",
    "# 4. run: criticality_score --repo https://github.com/bitcoin/bitcoin\n",
    "# >sample output:\n",
    "# '''     \n",
    "# ['name: bitcoin',\n",
    "#  'url: https://github.com/bitcoin/bitcoin',\n",
    "#  'language: C++',\n",
    "#  'created_since: 142',\n",
    "#  'updated_since: 0',\n",
    "#  'contributor_count: 961',\n",
    "#  'org_count: 4',\n",
    "#  'commit_frequency: 54.8',\n",
    "#  'recent_releases_count: 3',\n",
    "#  'updated_issues_count: 1920',\n",
    "#  'closed_issues_count: 1467',\n",
    "#  'comment_frequency: 2.7',\n",
    "#  'dependents_count: 348588',\n",
    "#  'criticality_score: 0.86651']\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'GITHUB_AUTH_TOKEN'\n",
    "os.environ[key] = 'xxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read '200_repos.csv' into DataFrame df\n",
    "df = pd.read_csv('cmc_repos_forge.csv')\n",
    "# keep 'source_code' location and 'forge'\n",
    "df_in = df[['source_code', 'forge']].copy()\n",
    "# subset dataframes for testing\n",
    "#df_in = df_in.iloc[96:101].copy()\n",
    "#df33 = dfs.iloc[:33].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   source_code  485 non-null    object\n",
      " 1   forge        436 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_in.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df200 = df_in.iloc[:199].copy()\n",
    "df400 = df_in.iloc[200:399].copy()\n",
    "df600 = df_in.iloc[400:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_code</th>\n",
       "      <th>forge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>https://github.com/BitcoinHEX/contract</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>https://github.com/tronprotocol/java-tron</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>https://github.com/lidofinance/lido-dao</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>https://github.com/FraxFinance/frax-solidity</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>https://github.com/osmosis-labs/osmosis</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>https://github.com/verasitytech</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>https://github.com/EveripediaNetwork</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>https://github.com/clover-network</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      source_code   forge\n",
       "200        https://github.com/BitcoinHEX/contract  github\n",
       "201     https://github.com/tronprotocol/java-tron  github\n",
       "202       https://github.com/lidofinance/lido-dao  github\n",
       "203  https://github.com/FraxFinance/frax-solidity  github\n",
       "204       https://github.com/osmosis-labs/osmosis  github\n",
       "..                                            ...     ...\n",
       "394                                           NaN     NaN\n",
       "395               https://github.com/verasitytech  github\n",
       "396                                           NaN     NaN\n",
       "397          https://github.com/EveripediaNetwork  github\n",
       "398             https://github.com/clover-network  github\n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# dfParse builds a dataFrame using bash output\n",
    "#  @output the command line output from calling criticality_score\n",
    "#  @firstTime boolean to initialize the dataframe the first loop call\n",
    "#  @dataframe the dataframe to be updated and returned\n",
    "# ------------------------------------------------\n",
    "def dfParse(output, firstUpdate, dataframe):\n",
    "    jout = json.dumps(output)    #jout is a str\n",
    "    out_dict = json.loads(jout)   #out_dict is a list\n",
    "    \n",
    "    # catch a possible traceback\n",
    "    if 'Traceback' in out_dict[0]:\n",
    "        print('found traceback')\n",
    "        return dataframe\n",
    "    \n",
    "    # prepare the dataFrame, initialize with column headers the same\n",
    "    # as the criticality_score output\n",
    "    df = pd.DataFrame(out_dict)\n",
    "    df.rename(columns = {0:'metric'}, inplace = True)\n",
    "    df[['metric','value']] = df.metric.str.split(expand = True)\n",
    "    df = df.transpose(copy = True)\n",
    "\n",
    "    # remove index column (with labels 'metric' & 'value')\n",
    "    # and reset the index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # rename columns according to first row; then drop the row\n",
    "    df = df.rename(columns = df.iloc[0]).drop(df.index[0])\n",
    "\n",
    "    if firstUpdate:\n",
    "        dataframe = df.copy()\n",
    "    else:\n",
    "        # append row[1] to df\n",
    "        dataframe = dataframe.append(df, ignore_index = True)   \n",
    "        \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# main loop requires dataFrame: 'df_in'\n",
    "#                      returns: 'df_out'\n",
    "# df_out does not have CMC_id and some will be missed;\n",
    "# should be able to merge back on 'url:'=='source_code'\n",
    "# ------------------------------------------------------\n",
    "# This takes a while, criticality_score has a built-in\n",
    "# rate limiter for handling github API limits. It still \n",
    "# gets stuck over about 200 url requests.\n",
    "# for example:\n",
    "# >Rate limit exceeded, sleeping till reset: 334 seconds.\n",
    "# ------------------------------------------------------\n",
    "# Sample Output:\n",
    "#  223 total projects evaluated\n",
    "#  153 criticality scores updated\n",
    "#  70 repos private or missing\n",
    "#  Total time elapsed: 22.6 minutes\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Need to chunk this better to avoid the rate limiting and\n",
    "# its confusing with 200/400/600, etc.\n",
    "# df_in = df200.copy()\n",
    "# df_in = df400.copy()\n",
    "df_in = df600.copy()\n",
    "\n",
    "start = time.time()\n",
    "total = 0\n",
    "updated = 0\n",
    "firstUpdate = True\n",
    "df_out = pd.DataFrame\n",
    "\n",
    "for row in df_in.itertuples():\n",
    "    # proceed if github and source_code is a string and not private\n",
    "    if (row.forge == 'github') and isinstance(row.source_code, str) and (row.source_code != 'private'):\n",
    "        cmd = 'criticality_score --repo ' + row.source_code\n",
    "        print(row.source_code)\n",
    "        output = !{cmd}\n",
    "        # if first element is ['name':'bitcoin'], output is as expected, can parse\n",
    "        if 'name' in output[0]: \n",
    "            df_out = dfParse(output, firstUpdate, df_out)\n",
    "            firstUpdate = False\n",
    "            updated += 1\n",
    "    total += 1\n",
    "    sys.stdout.write(\".\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# log some output with a timer\n",
    "print('\\n',str(df_in.shape[0]), 'total projects evaluated\\n', \n",
    "      str(updated), 'criticality scores updated\\n', \n",
    "      str(total - updated), 'repos private or missing\\n', \n",
    "      'Total time elapsed:', round((time.time() - start)/60, 1), 'minutes')\n",
    "\n",
    "# df200 = df_out.copy()\n",
    "# df400 = df_out.copy()\n",
    "df600 = df_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out new data\n",
    "# df200.to_csv('crit_output_all_200.csv', encoding='utf-8', index = 0)\n",
    "# df400.to_csv('crit_output_all_400.csv', encoding='utf-8', index = 0)\n",
    "df600.to_csv('crit_output_all_600.csv', encoding='utf-8', index = 0)\n",
    "# dft = df_out[['url:','criticality_score:']].copy()\n",
    "# dft.to_csv('crit_only.csv', encoding='utf-8', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156 entries, 0 to 155\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   name:                   156 non-null    object \n",
      " 1   url:                    156 non-null    object \n",
      " 2   language:               156 non-null    object \n",
      " 3   created_since:          156 non-null    int64  \n",
      " 4   updated_since:          156 non-null    int64  \n",
      " 5   contributor_count:      156 non-null    int64  \n",
      " 6   org_count:              156 non-null    int64  \n",
      " 7   commit_frequency:       156 non-null    float64\n",
      " 8   recent_releases_count:  156 non-null    int64  \n",
      " 9   updated_issues_count:   156 non-null    int64  \n",
      " 10  closed_issues_count:    156 non-null    int64  \n",
      " 11  comment_frequency:      156 non-null    float64\n",
      " 12  dependents_count:       156 non-null    int64  \n",
      " 13  criticality_score:      156 non-null    float64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 17.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# read in chunked data\n",
    "# df200 = pd.read_csv('crit_output_all_0-200.csv')\n",
    "# df400 = pd.read_csv('crit_output_all_200-400.csv')\n",
    "# df600 = pd.read_csv('crit_output_all_400-600.csv')\n",
    "# dfcrit200 = pd.read_csv('crit_only_0-200.csv')\n",
    "# dfcrit400 = pd.read_csv('crit_only_200-400.csv')\n",
    "# dfcrit600 = pd.read_csv('crit_only_400-600.csv')\n",
    "df200 = pd.read_csv('crit_output_all_200.csv')\n",
    "df200.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data frames\n",
    "dfall = pd.concat([df200, df400, df600], ignore_index=True)\n",
    "# dfcrit = pd.concat([dfcrit200, dfcrit400, dfcrit600], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out merged frames\n",
    "dfall.to_csv('crit_output_all.csv', encoding='utf-8', index = 0)\n",
    "# dfcrit.to_csv('crit_only.csv', encoding='utf-8', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 251 entries, 0 to 250\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   name:                   251 non-null    object\n",
      " 1   url:                    251 non-null    object\n",
      " 2   language:               251 non-null    object\n",
      " 3   created_since:          251 non-null    object\n",
      " 4   updated_since:          251 non-null    object\n",
      " 5   contributor_count:      251 non-null    object\n",
      " 6   org_count:              251 non-null    object\n",
      " 7   commit_frequency:       251 non-null    object\n",
      " 8   recent_releases_count:  251 non-null    object\n",
      " 9   updated_issues_count:   251 non-null    object\n",
      " 10  closed_issues_count:    251 non-null    object\n",
      " 11  comment_frequency:      251 non-null    object\n",
      " 12  dependents_count:       251 non-null    object\n",
      " 13  criticality_score:      251 non-null    object\n",
      "dtypes: object(14)\n",
      "memory usage: 27.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dfall.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
