{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickhouse Database Workflow\n",
    "1. download github data in native clickhouse format (74.6 gb, ~10hours to download)\n",
    "2. clickhouse server must be running\n",
    "see: https://clickhouse.tech/docs/en/getting-started/install/\n",
    " >sudo service clickhouse-server start (may need sudo -u japple)\n",
    " >clickhouse-client\n",
    "\n",
    "## Insert the database into clickhouse\n",
    "3. create the db tables:\n",
    " >CREATE TABLE github_events ...\n",
    " see https://ghe.clickhouse.tech/\n",
    "4. Insert the DB file into clickhouse <E:\\Documents\\Clickhouse Github data\\github_events_v2.native.xz>\n",
    "  (~2-300 gb? takes ~4 hours to insert)\n",
    "5. run code here to connect to clickhouse client and manipulate data\n",
    "\n",
    "Note the clickhouse driver (python) communicates with the clickhouse server via a native TCP/IP protocol that ships data as typed values; this will cause problems when INSERT-ing into a DB, however I don't see this as an issue\n",
    "\n",
    "## Documentation\n",
    "For better (& future) documentation see:\n",
    "* https://stackoverflow.com/questions/9195455/how-to-document-a-method-with-parameters\n",
    "* https://www.sphinx-doc.org/en/master/usage/restructuredtext/domains.html#python-signatures\n",
    "\n",
    "## local Clickhouse DB stuffs\n",
    "#### find the earliest DB instance query:\n",
    "```sql\n",
    "SELECT min(created_at) AS first_seen\n",
    "FROM github_events\n",
    "WHERE toYear(created_at) < 2012\n",
    "\n",
    "┌──────────first_seen─┐\n",
    "│ 2011-02-12 13:00:00 │\n",
    "└─────────────────────┘\n",
    "```\n",
    "#### find the earliest 10 commits:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    created_at,\n",
    "    repo_name\n",
    "FROM github_events\n",
    "WHERE (toYear(created_at) < 2012) AND (toMonth(created_at) < 3)\n",
    "ORDER BY created_at ASC\n",
    "LIMIT 10\n",
    "\n",
    "Query id: 4703822a-986f-4a0f-a592-c031c945da0d\n",
    "\n",
    "┌──────────created_at─┬─repo_name────────────────────┐\n",
    "│ 2011-02-12 13:00:00 │ projectblacklight/blacklight │\n",
    "│ 2011-02-12 13:00:06 │ ezmobius/super-nginx         │\n",
    "│ 2011-02-12 13:00:10 │ /                            │\n",
    "│ 2011-02-12 13:00:10 │ Selenium2/Selenium2          │\n",
    "│ 2011-02-12 13:00:17 │ appcelerator/webkit_titanium │\n",
    "│ 2011-02-12 13:00:19 │ urzuae/spd                   │\n",
    "│ 2011-02-12 13:00:22 │ arokem/nitime                │\n",
    "│ 2011-02-12 13:00:23 │ jkbrooks/sample_app          │\n",
    "│ 2011-02-12 13:00:25 │ networkx/networkx            │\n",
    "│ 2011-02-12 13:00:27 │ spurious/clang-mirror        │\n",
    "└─────────────────────┴──────────────────────────────┘\n",
    "20 rows in set. Elapsed: 105.222 sec. Processed 2.78 billion rows, 18.30 GB (26.38 million rows/s., 173.93 MB/s.)\n",
    "```\n",
    "\n",
    "------------------------------------------------------\n",
    "#### find the latest 10 commits\n",
    "\n",
    "Useful to seeing when the last entry in the DB was\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    created_at,\n",
    "    repo_name\n",
    "FROM github_events\n",
    "WHERE (toYear(created_at) >= 2020) AND (toMonth(created_at) > 11)\n",
    "ORDER BY created_at DESC\n",
    "LIMIT 20\n",
    "\n",
    "Query id: 2d80f96a-6db0-451e-9a69-6143e5ca915c\n",
    "\n",
    "┌──────────created_at─┬─repo_name───────────────────────────────┐\n",
    "│ 2020-12-07 08:59:59 │ Technigo/project-labyrinth              │\n",
    "│ 2020-12-07 08:59:59 │ HUPO-PSI/mzQC                           │\n",
    "│ 2020-12-07 08:59:59 │ elrumo/macOS_Big_Sur_icons_replacements │\n",
    "│ 2020-12-07 08:59:59 │ MetaCipher/sdl-2.0-textures             │\n",
    "│ 2020-12-07 08:59:59 │ womega/Covid19_project                  │\n",
    "│ 2020-12-07 08:59:59 │ theGreatWhiteShark/hydrogen             │\n",
    "│ 2020-12-07 08:59:59 │ diaslais/projeto-ohana                  │\n",
    "│ 2020-12-07 08:59:59 │ commit-b0t/commit-b0t                   │\n",
    "│ 2020-12-07 08:59:59 │ TheGameCreators/AGK-Studio              │\n",
    "│ 2020-12-07 08:59:59 │ shortland/May-Automation                │\n",
    "│ 2020-12-07 08:59:59 │ randomperson190/ControlDeOrganicos      │\n",
    "│ 2020-12-07 08:59:59 │ markgardie/WebApp                       │\n",
    "│ 2020-12-07 08:59:59 │ Lombiq/Orchard.AngularJS                │\n",
    "│ 2020-12-07 08:59:59 │ Hugobros3/chunkstories-api              │\n",
    "│ 2020-12-07 08:59:59 │ BenCrespoDuke/HackDuke                  │\n",
    "│ 2020-12-07 08:59:59 │ AndrewUsher/tvmaze-graphql-server       │\n",
    "│ 2020-12-07 08:59:59 │ HUPO-PSI/mzQC                           │\n",
    "│ 2020-12-07 08:59:59 │ brothersu/L2ch05                        │\n",
    "│ 2020-12-07 08:59:59 │ becklabs/sensor-buoy                    │\n",
    "│ 2020-12-07 08:59:59 │ aboodKh/cra-devops                      │\n",
    "└─────────────────────┴─────────────────────────────────────────┘\n",
    "\n",
    "20 rows in set. Elapsed: 46.208 sec. Processed 2.81 billion rows, 53.47 GB (60.71 million rows/s., 1.16 GB/s.)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the environment\n",
    "# import sys; sys.prefix\n",
    "\n",
    "# # check the jupyter directory\n",
    "# import os\n",
    "# os.getcwd()\n",
    "\n",
    "# # to install clickhouse support\n",
    "# !{sys.executable} -m pip install clickhouse-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys,time\n",
    "import math\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from clickhouse_driver import Client\n",
    "# dependencies\n",
    "# >ipython-sql\n",
    "# install by command prompt:\n",
    "# >conda install -yc conda-forge ipython-sql\n",
    "client = Client('localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame df\n",
    "# cmc_repos_forge.csv has been copied into this folder\n",
    "# NaN is assigned to empty cells\n",
    "dfs = pd.read_csv('cmc_repos_forge.csv', index_col=0)\n",
    "df = dfs[['repo','forge']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # subset dataframes for testing\n",
    "# # use .copy() as slicing will not allow for assignment\n",
    "# df10 = df.iloc[:10].copy()\n",
    "# df33 = df.iloc[:33].copy()\n",
    "\n",
    "# # test to show connectivity\n",
    "# # expected output: [('github_events',)]\n",
    "# client.execute('SHOW TABLES FROM default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# --   S Q L   Q U E R Y   S T R I N G S   -----------\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ----S T A R S --------------------------------------\n",
    "# ----------------------------------------------------\n",
    "stars_L = '''\n",
    "SELECT count() \n",
    "FROM github_events \n",
    "WHERE (event_type = 'WatchEvent') AND repo_name =\n",
    "'''\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ----F O R K S --------------------------------------\n",
    "# ----------------------------------------------------\n",
    "forks_L = '''\n",
    "SELECT count()\n",
    "FROM github_events \n",
    "WHERE (event_type = 'ForkEvent') AND repo_name =\n",
    "'''\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ----A U T H O R S-----------------------------------\n",
    "# ----------------------------------------------------\n",
    "# Calculates a monthly average from previous 3 months\n",
    "# excluding current month because it is in progress\n",
    "# \n",
    "# modify for static clickhouse data which stops at 2020-12-07\n",
    "# >>created_at >= dateSub(MONTH, 6,toStartOfMonth(now())) AND\n",
    "# >>created_at < dateSub(MONTH, 3,toStartOfMonth(now()))\n",
    "#\n",
    "authors_L = '''\n",
    "SELECT\n",
    "    ROUND( SUM(authors) / COUNT(month), 2) AS average\n",
    "FROM\n",
    "(\n",
    "    SELECT \n",
    "        uniq(actor_login) AS authors,\n",
    "        toMonth(created_at) AS month,\n",
    "        toYear(created_at) AS year\n",
    "    FROM github_events\n",
    "    WHERE event_type IN ('PullRequestEvent', 'IssuesEvent', 'IssueCommentEvent', 'PullRequestReviewCommentEvent') AND\n",
    "        repo_name = \n",
    "'''\n",
    "# have to go back to Oct-Dec 2020 in the static database\n",
    "# this is 17-14 months ago from now\n",
    "authors_R = '''AND\n",
    "        /*created_at >= dateSub(MONTH, 3,toStartOfMonth(now())) AND\n",
    "        created_at < toStartOfMonth(now())*/\n",
    "        created_at >= dateSub(MONTH, 17,toStartOfMonth(now())) AND\n",
    "        created_at < dateSub(MONTH, 14,toStartOfMonth(now()))\n",
    "    GROUP BY month, year\n",
    "    ORDER BY year DESC, month DESC\n",
    ")'''\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ----C O M M I T S-----------------------------------\n",
    "# ----------------------------------------------------\n",
    "# Calculates a monthly average from previous 3 months\n",
    "# excluding current month because it is in progress\n",
    "#\n",
    "# modify for static clickhouse data which stops at 2020-12-07:\n",
    "# >>created_at >= dateSub(MONTH, 6,toStartOfMonth(now())) AND\n",
    "# >>created_at < dateSub(MONTH, 3,toStartOfMonth(now()))\n",
    "# \n",
    "# note: there will be moderate timezone discrepancies, especially \n",
    "#       when calculating near the first of the month\n",
    "#\n",
    "commits_L ='''\n",
    "SELECT ROUND( SUM(sum_push_distinct) / COUNT(month), 2) AS average\n",
    "FROM\n",
    "(\n",
    "    SELECT SUM(push_distinct_size) AS sum_push_distinct, \n",
    "        toMonth(created_at) AS month,\n",
    "        toYear(created_at) AS year\n",
    "    FROM github_events\n",
    "    WHERE repo_name = \n",
    "'''\n",
    "\n",
    "commits_R = '''\n",
    "AND \n",
    "        event_type = 'PushEvent' AND\n",
    "        /*created_at >= dateSub(MONTH, 3,toStartOfMonth(now())) AND\n",
    "        created_at < toStartOfMonth(now())*/\n",
    "        created_at >= dateSub(MONTH, 17,toStartOfMonth(now())) AND\n",
    "        created_at < dateSub(MONTH, 14,toStartOfMonth(now()))\n",
    "    GROUP BY month, year\n",
    "    ORDER BY year DESC, month DESC\n",
    ")'''\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ----C O M M E N T S---------------------------------\n",
    "# ----------------------------------------------------\n",
    "# Calculates a monthly average from previous 3 months\n",
    "# excluding current month because it is in progress\n",
    "#\n",
    "# total COMMENTS includes all commenting activity\n",
    "# any comments counts as activity and increase engagement\n",
    "# there are 3 event_type comment events:\n",
    "# >CommitCommentEvent\n",
    "# >IssueCommentEvent\n",
    "# >CommitCommentEvent\n",
    "#\n",
    "comments_L='''\n",
    "SELECT ROUND(SUM(total) / COUNT(month), 2) AS average\n",
    "FROM\n",
    "(\n",
    "    SELECT\n",
    "        (uniqIf(comment_id, event_type = 'PullRequestReviewCommentEvent') + \n",
    "         uniqIf(comment_id, event_type = 'IssueCommentEvent')) + \n",
    "         uniqIf(comment_id, event_type = 'CommitCommentEvent') AS total,\n",
    "        toMonth(created_at) AS month,\n",
    "        toYear(created_at) AS year\n",
    "    FROM github_events\n",
    "    WHERE repo_name =  \n",
    "'''\n",
    "\n",
    "comments_R='''\n",
    "    AND \n",
    "        (created_at >= (toStartOfMonth(now()) - toIntervalMonth(17)) ) AND \n",
    "        (created_at <  (toStartOfMonth(now()) - toIntervalMonth(14)) )\n",
    "    GROUP BY\n",
    "        month,\n",
    "        year\n",
    "    ORDER BY\n",
    "        year DESC,\n",
    "        month DESC\n",
    ")'''\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ----P U L L   R E Q U E S T S   O P E N E D---------\n",
    "# ----------------------------------------------------\n",
    "# Calculates a monthly average from previous 3 months\n",
    "# excluding current month because it is in progress\n",
    "#\n",
    "PR_L='''\n",
    "SELECT\n",
    "    ROUND( SUM(opened) / COUNT(month), 2) AS average\n",
    "FROM\n",
    "(\n",
    "    SELECT  \n",
    "        SUM(action = 'opened') AS opened,\n",
    "        toYear(created_at) AS year, \n",
    "        toMonth(created_at) AS month\n",
    "    FROM github_events\n",
    "    WHERE repo_name = \n",
    "'''\n",
    "\n",
    "PR_R='''\n",
    "    AND \n",
    "        (event_type = 'PullRequestEvent') AND \n",
    "        (created_at >= (toStartOfMonth(now()) - toIntervalMonth(17)) ) AND \n",
    "        (created_at <  (toStartOfMonth(now()) - toIntervalMonth(14)) )\n",
    "    GROUP BY\n",
    "        month,\n",
    "        year\n",
    "    ORDER BY\n",
    "        year DESC,\n",
    "        month DESC\n",
    ")'''\n",
    "\n",
    "# -------------------------------------------\n",
    "# --- A V E R A G E  C A L C U L A T I O N\n",
    "# -------------------------------------------\n",
    "# timestamp set to 2019-11-01 to allow for a year of activity\n",
    "#\n",
    "avg_issue_time_L = '''\n",
    "WITH repo_name =\n",
    "'''\n",
    "avg_issue_time_R = '''\n",
    "AS repo,\n",
    "     sum(dateDiff('minute', toDateTime(opened), toDateTime(closed)))/60/24 AS total_days,\n",
    "     round(dateDiff('second', toDateTime(opened), toDateTime(closed)),2)/60 AS mins_open, \n",
    "\t count() AS num_issues,\n",
    "     (event_type = 'IssuesEvent' OR event_type = 'PullRequestEvent') AS event,\n",
    "     created_at >= toDateTime('2019-11-01') AS created\n",
    "SELECT  round( total_days / num_issues, 2) AS average_response_time_days\n",
    "FROM\n",
    "(\n",
    "    SELECT *\n",
    "    FROM\n",
    "   (\n",
    "        SELECT \tnumber,\n",
    "\t\tcreated_at AS opened\n",
    "\tFROM github_events \n",
    "\tWHERE \trepo AND\n",
    "\t\tevent AND\n",
    "\t\taction = 'opened' AND\n",
    "\t\tcreated\n",
    "    ) AS t1\n",
    "    INNER JOIN\n",
    "    (\n",
    "        SELECT \tnumber,\n",
    "\t\tcreated_at AS closed\n",
    "\tFROM github_events \n",
    "\tWHERE \trepo AND\n",
    "\t\tevent AND\n",
    "\t\taction = 'closed' AND\n",
    "\t\tcreated\n",
    "    ) AS t2 USING (number)\n",
    ")\n",
    "WHERE mins_open > 5\n",
    "'''\n",
    "\n",
    "# -------------------------------------------\n",
    "# --  M E D I A N    C A L C U L A T I O N\n",
    "# -------------------------------------------\n",
    "# timestamp set to 2019-11-01 to allow for a year of activity\n",
    "#\n",
    "med_issue_time_L = '''\n",
    "WITH repo_name =\n",
    "'''\n",
    "med_issue_time_R = '''\n",
    "AS repo,\n",
    "     round(dateDiff('second', toDateTime(opened), toDateTime(closed)),2)/60 AS mins_open,\n",
    "     round(dateDiff('second', toDateTime(opened), toDateTime(closed)),2)/60/60/24 AS days_open, \n",
    "     (event_type = 'IssuesEvent' OR event_type = 'PullRequestEvent') AS event,\n",
    "     created_at >= toDateTime('2019-11-01') AS created\n",
    "SELECT  round(medianDeterministic(days_open, 1),2) as median_response_time_days\n",
    "FROM\n",
    "(\n",
    "    SELECT *\n",
    "    FROM\n",
    "   (\n",
    "        SELECT \tnumber,\n",
    "\t\tcreated_at AS opened\n",
    "\tFROM github_events \n",
    "\tWHERE \trepo AND\n",
    "\t\tevent AND\n",
    "\t\taction = 'opened' AND\n",
    "\t\tcreated\n",
    "    ) AS t1\n",
    "    INNER JOIN\n",
    "    (\n",
    "        SELECT \tnumber,\n",
    "\t\tcreated_at AS closed\n",
    "\tFROM github_events \n",
    "\tWHERE \trepo AND\n",
    "\t\tevent AND\n",
    "\t\taction = 'closed' AND\n",
    "\t\tcreated\n",
    "    ) AS t2 USING (number)\n",
    ")\n",
    "WHERE mins_open > 5\n",
    "'''\n",
    "\n",
    "# ---------------------------------------------\n",
    "# --- L O N G E V I T Y  C A L C U L A T I O N\n",
    "# ---------------------------------------------\n",
    "# searches the repo for all activity by a contributor\n",
    "# excludes those that step in 'one-time'\n",
    "# such as starring or forking or leaving a comment and never returning\n",
    "# this excludes devs that work on other projects \n",
    "# (only calculates from single repo)\n",
    "#---------------------------------------\n",
    "# view multiple author's days active\n",
    "#---------------------------------------\n",
    "'''\n",
    "WITH dateDiff('day', toDateTime(earliest_seen), toDateTime(last_seen)) AS days_active\n",
    "SELECT\n",
    "    days_active,\n",
    "    actor_login,\n",
    "    last_seen\n",
    "FROM\n",
    "(\n",
    "    SELECT\n",
    "        MIN(created_at) AS earliest_seen,\n",
    "        MAX(created_at) AS last_seen,\n",
    "        days_active,\n",
    "        actor_login\n",
    "    FROM github_events\n",
    "    WHERE repo_name = 'bitcoin/bitcoin'\n",
    "    GROUP BY actor_login\n",
    "    ORDER BY days_active DESC\n",
    ")\n",
    "WHERE days_active > 0\n",
    "LIMIT 100\n",
    "'''\n",
    "\n",
    "# ---------------------------------------------\n",
    "# calculate A V G.  D E V.  L O N G E V I T Y\n",
    "# ---------------------------------------------\n",
    "avg_longevity_L = '''\n",
    "WITH dateDiff('day', toDateTime(earliest_seen), \n",
    "\ttoDateTime(last_seen)) AS days_active\n",
    "SELECT ROUND((SUM(days_active) / count() ),2) AS avg_dev_days_active\n",
    "FROM\n",
    "(  SELECT MIN(created_at) AS earliest_seen, \n",
    "\t\tMAX(created_at) AS last_seen, \n",
    "\t\tdays_active, \n",
    "\t\tactor_login, \n",
    "\t\tcount()\n",
    "   FROM github_events \n",
    "   WHERE repo_name = \n",
    "'''\n",
    "avg_longevity_R = '''\n",
    "GROUP by actor_login\n",
    "   ORDER by days_active DESC\n",
    ")\n",
    "WHERE days_active > 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# ----T E S T   Q U E R I E S-------------------------\n",
    "# ----------------------------------------------------\n",
    "# some of my testing notes\n",
    "\n",
    "query_test_noStars = '''\n",
    "SELECT \n",
    "    count() \n",
    "FROM github_events \n",
    "WHERE event_type = 'WatchEvent' \n",
    "    AND repo_name =\n",
    "'bitcoin/bitcoin'\n",
    "'''\n",
    "\n",
    "query2 = '''\n",
    "SELECT \n",
    "    count() \n",
    "FROM github_events \n",
    "WHERE event_type = 'WatchEvent' \n",
    "    AND repo_name =\n",
    "'HuobiGroup/huobi-eco-chain'\n",
    "'''\n",
    "\n",
    "repo = '''\n",
    "'HuobiGroup/huobi-eco-chain' \n",
    "'''\n",
    "\n",
    "QUERY_AUTHORS_TEST = '''\n",
    "SELECT\n",
    "    ROUND( SUM(authors) / COUNT(month), 2) AS average\n",
    "FROM\n",
    "(\n",
    "    SELECT \n",
    "        uniq(actor_login) AS authors,\n",
    "        toMonth(created_at) AS month,\n",
    "        toYear(created_at) AS year\n",
    "    FROM github_events\n",
    "    WHERE event_type IN ('PullRequestEvent', 'IssuesEvent', 'IssueCommentEvent', 'PullRequestReviewCommentEvent') AND\n",
    "        repo_name = 'bitcoin/bitcoin' AND\n",
    "        created_at >= dateSub(MONTH, 3,toStartOfMonth(now())) AND\n",
    "        created_at < toStartOfMonth(now())\n",
    "    GROUP BY month, year\n",
    "    ORDER BY year DESC, month DESC\n",
    ")'''\n",
    "\n",
    "QUERY_COMMITS_TEST = '''\n",
    "SELECT ROUND( SUM(sum_push_distinct) / COUNT(month), 2) AS average\n",
    "FROM\n",
    "(\n",
    "    SELECT SUM(push_distinct_size) AS sum_push_distinct, \n",
    "        toMonth(created_at) AS month,\n",
    "        toYear(created_at) AS year\n",
    "    FROM github_events\n",
    "    WHERE repo_name = 'bitcoin/bitcoin' AND \n",
    "        event_type = 'PushEvent' AND\n",
    "        /*created_at >= dateSub(MONTH, 3,toStartOfMonth(now())) AND\n",
    "        created_at < toStartOfMonth(now())*/\n",
    "        created_at >= dateSub(MONTH, 17,toStartOfMonth(now())) AND\n",
    "        created_at < dateSub(MONTH, 14,toStartOfMonth(now()))\n",
    "    GROUP BY month, year\n",
    "    ORDER BY year DESC, month DESC\n",
    ")\n",
    "'''\n",
    "\n",
    "# expected output here:\n",
    "# [(nan,)]\n",
    "query_test_zero='''\n",
    "SELECT ROUND( SUM(sum_push_distinct) / COUNT(month), 2) AS average\n",
    "FROM\n",
    "(\n",
    "    SELECT SUM(push_distinct_size) AS sum_push_distinct, \n",
    "        toMonth(created_at) AS month,\n",
    "        toYear(created_at) AS year\n",
    "    FROM github_events\n",
    "    WHERE repo_name = 'Uniswap/uniswap-v2-core' AND \n",
    "        event_type = 'PushEvent' AND\n",
    "        /*created_at >= dateSub(MONTH, 3,toStartOfMonth(now())) AND\n",
    "        created_at < toStartOfMonth(now())*/\n",
    "        created_at >= dateSub(MONTH, 6,toStartOfMonth(now())) AND\n",
    "        created_at < dateSub(MONTH, 3,toStartOfMonth(now()))\n",
    "    GROUP BY month, year\n",
    "    ORDER BY year DESC, month DESC\n",
    ")'''\n",
    "\n",
    "\n",
    "# View distribution of comments by month for a single year\n",
    "'''\n",
    "SELECT \n",
    "    uniq(comment_id) AS total_comments,\n",
    "    uniqIf(comment_id, event_type = 'PullRequestReviewCommentEvent') AS pr_comments,\n",
    "    uniqIf(comment_id, event_type = 'IssueCommentEvent') AS issue_comments,\n",
    "    uniqIf(comment_id, event_type = 'CommitCommentEvent') AS commit_comments,\n",
    "    toMonth(created_at) AS month,\n",
    "    toYear(created_at) AS year\n",
    "FROM github_events\n",
    "WHERE \n",
    "   repo_name = 'bitcoin/bitcoin' AND\n",
    "   toYear(created_at) >= 2020\n",
    "GROUP BY month, year\n",
    "ORDER BY year DESC, month DESC\n",
    "'''\n",
    "\n",
    "\n",
    "# only Sept/Oct/Nov 2020 #\n",
    "QUERY_COMMENTS_TEST='''\n",
    "SELECT ROUND(SUM(total) / COUNT(month), 2) AS average\n",
    "FROM\n",
    "(\n",
    "    SELECT\n",
    "        (uniqIf(comment_id, event_type = 'PullRequestReviewCommentEvent') + \n",
    "         uniqIf(comment_id, event_type = 'IssueCommentEvent')) + \n",
    "         uniqIf(comment_id, event_type = 'CommitCommentEvent') AS total,\n",
    "        toMonth(created_at) AS month,\n",
    "        toYear(created_at) AS year\n",
    "    FROM github_events\n",
    "    WHERE (repo_name = 'bitcoin/bitcoin') AND \n",
    "          (created_at >= (toStartOfMonth(now()) - toIntervalMonth(17)) ) AND \n",
    "          (created_at <  (toStartOfMonth(now()) - toIntervalMonth(14)) )\n",
    "    GROUP BY\n",
    "        month,\n",
    "        year\n",
    "    ORDER BY\n",
    "        year DESC,\n",
    "        month DESC\n",
    ")'''\n",
    "\n",
    "# view all PR activity sorted into: opened, closed, reopened\n",
    "'''\n",
    "SELECT  COUNT() AS total,\n",
    "    SUM(action = 'opened') AS opened,\n",
    "    SUM(action = 'closed') AS closed,\n",
    "    SUM(action = 'reopened') AS reopened,\n",
    "    toYear(created_at) AS year, \n",
    "    toMonth(created_at) AS month\n",
    "FROM github_events\n",
    "WHERE repo_name = 'bitcoin/bitcoin' AND \n",
    "    toYear(created_at) >= '2019' AND \n",
    "    event_type = 'PullRequestEvent'\n",
    "GROUP BY month, year\n",
    "ORDER BY year DESC, month DESC\n",
    "'''\n",
    "\n",
    "# monthly average over previous 3 months\n",
    "'''\n",
    "SELECT ROUND(SUM(opened) / COUNT(month), 2) AS average\n",
    "FROM\n",
    "(\n",
    "    SELECT\n",
    "        SUM(action = 'opened') AS opened,\n",
    "        toYear(created_at) AS year,\n",
    "        toMonth(created_at) AS month\n",
    "    FROM github_events\n",
    "    WHERE (repo_name = 'bitcoin/bitcoin') AND \n",
    "          (event_type = 'PullRequestEvent') AND \n",
    "          (created_at >= (toStartOfMonth(now()) - toIntervalMonth(18)) ) AND \n",
    "          (created_at <  (toStartOfMonth(now()) - toIntervalMonth(15)) )\n",
    "    GROUP BY\n",
    "        month,\n",
    "        year\n",
    "    ORDER BY\n",
    "        year DESC,\n",
    "        month DESC\n",
    ")'''\n",
    "\n",
    "# average response time\n",
    "# includes 'IssuesEvent' or 'PullRequestEvent'\n",
    "avg_issue_time_test = '''\n",
    "WITH repo_name = 'bitcoin/bitcoin' AS repo,\n",
    "     sum(dateDiff('minute', toDateTime(opened), toDateTime(closed)))/60/24 AS total_days,\n",
    "     round(dateDiff('second', toDateTime(opened), toDateTime(closed)),2)/60 AS mins_open, \n",
    "\t count() AS num_issues,\n",
    "     (event_type = 'IssuesEvent' OR event_type = 'PullRequestEvent') AS event,\n",
    "     created_at >= toDateTime('2019-11-01') AS created\n",
    "SELECT  round( total_days / num_issues, 2) AS average_response_time_days\n",
    "FROM\n",
    "(\n",
    "    SELECT *\n",
    "    FROM\n",
    "   (\n",
    "        SELECT \tnumber,\n",
    "\t\tcreated_at AS opened\n",
    "\tFROM github_events \n",
    "\tWHERE \trepo AND\n",
    "\t\tevent AND\n",
    "\t\taction = 'opened' AND\n",
    "\t\tcreated\n",
    "    ) AS t1\n",
    "    INNER JOIN\n",
    "    (\n",
    "        SELECT \tnumber,\n",
    "\t\tcreated_at AS closed\n",
    "\tFROM github_events \n",
    "\tWHERE \trepo AND\n",
    "\t\tevent AND\n",
    "\t\taction = 'closed' AND\n",
    "\t\tcreated\n",
    "    ) AS t2 USING (number)\n",
    ")\n",
    "WHERE mins_open > 5\n",
    "'''\n",
    "\n",
    "# median response time\n",
    "# includes 'IssuesEvent' or 'PullRequestEvent'\n",
    "med_issue_time_test = '''\n",
    "WITH repo_name = 'bitcoin/bitcoin' AS repo,\n",
    "     round(dateDiff('second', toDateTime(opened), toDateTime(closed)),2)/60 AS mins_open,\n",
    "     round(dateDiff('second', toDateTime(opened), toDateTime(closed)),2)/60/60/24 AS days_open, \n",
    "     (event_type = 'IssuesEvent' OR event_type = 'PullRequestEvent') AS event,\n",
    "     created_at >= toDateTime('2019-11-01') AS created\n",
    "SELECT  round(medianDeterministic(days_open, 1),2) as median_response_time_days\n",
    "FROM\n",
    "(\n",
    "    SELECT *\n",
    "    FROM\n",
    "   (\n",
    "        SELECT \tnumber,\n",
    "\t\tcreated_at AS opened\n",
    "\tFROM github_events \n",
    "\tWHERE \trepo AND\n",
    "\t\tevent AND\n",
    "\t\taction = 'opened' AND\n",
    "\t\tcreated\n",
    "    ) AS t1\n",
    "    INNER JOIN\n",
    "    (\n",
    "        SELECT \tnumber,\n",
    "\t\tcreated_at AS closed\n",
    "\tFROM github_events \n",
    "\tWHERE \trepo AND\n",
    "\t\tevent AND\n",
    "\t\taction = 'closed' AND\n",
    "\t\tcreated\n",
    "    ) AS t2 USING (number)\n",
    ")\n",
    "WHERE mins_open > 5\n",
    "'''\n",
    "\n",
    "# average developer days active in the repo\n",
    "'''\n",
    "WITH dateDiff('day', toDateTime(earliest_seen), toDateTime(last_seen)) AS days_active\n",
    "SELECT ROUND(SUM(days_active) / count(), 2) AS avg_dev_days_active\n",
    "FROM\n",
    "(\n",
    "    SELECT\n",
    "        MIN(created_at) AS earliest_seen,\n",
    "        MAX(created_at) AS last_seen,\n",
    "        days_active,\n",
    "        actor_login,\n",
    "        count()\n",
    "    FROM github_events\n",
    "    WHERE repo_name = 'bitcoin/bitcoin'\n",
    "    GROUP BY actor_login\n",
    "    ORDER BY days_active DESC\n",
    ")\n",
    "WHERE days_active > 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# -- R U N   Q U E R Y ------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "#\n",
    "def runQuery(column_name, df, query_L, query_R=''):\n",
    "    \"\"\"executes a Clickhouse query on a Pandas dataframe;\n",
    "    the complete query is a string 'query_L + repo + query_R' where\n",
    "    repo is the name of a github repository contained in df\n",
    "    \n",
    "    Keyword arguments:\n",
    "    column_name -- the new column to be added to the dataframe, e.g. 'stars'\n",
    "    df -- the pandas dataframe containing 'repo' and 'forge' columns\n",
    "    query_L -- the SQL string preceeding the github repository name\n",
    "    query_R -- the SQL string postceding the github repository name, this can be empty by default\n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    num = 0\n",
    "    num_u = 0\n",
    "    for row in df.itertuples():\n",
    "        # only github for now as client is connected to github_events DB\n",
    "        if row.forge == 'github':\n",
    "            repo = row.repo\n",
    "            # skip the NaN repos\n",
    "            if type(repo) == str:\n",
    "                query = query_L + '\\'' + repo + '\\'' + query_R\n",
    "                result = client.execute(query)\n",
    "                num += 1\n",
    "\n",
    "                # query returns a tuple of list elements accessible by [first list][first item]\n",
    "                # empty list returns -1 meaning it has to be manually verified\n",
    "                # average of zero returns a nan\n",
    "                if len(result) == 0:\n",
    "                    df.at[row.Index, column_name] = -1\n",
    "                elif math.isnan(result[0][0]):\n",
    "                    df.at[row.Index, column_name] = 0\n",
    "                else: \n",
    "                    df.at[row.Index, column_name] = result[0][0]\n",
    "                    num_u += 1\n",
    "\n",
    "        # proof-of-life\n",
    "        if num % 10 == 0: sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    # some log info\n",
    "    now = datetime.now()\n",
    "    elapsed = (now - start).total_seconds()\n",
    "    output = column_name + ': ' + str(num) + ' repos queried and ' + str(num_u) + ' updated; Query took ' + str(round(elapsed,2)) + ' seconds.'\n",
    "    print('\\n' + output)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................\n",
      "stars: 430 repos queried and 430 updated; Query took 3.14 seconds.\n"
     ]
    }
   ],
   "source": [
    "# all available queries\n",
    "runQuery('stars', df, stars_L)\n",
    "runQuery('forks', df, forks_L)\n",
    "runQuery('authors', df, authors_L, authors_R)\n",
    "runQuery('commits', df, commits_L, commits_R)\n",
    "runQuery('comments', df, comments_L, comments_R)\n",
    "runQuery('PR_open', df, PR_L, PR_R)\n",
    "runQuery('avg_resp_time', df, avg_issue_time_L, avg_issue_time_R)\n",
    "runQuery('med_resp_time', df, med_issue_time_L, med_issue_time_R)\n",
    "runQuery('avg_longevity_days', df, avg_longevity_L, avg_longevity_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to: clickhouse_queries_updated_25-03-2022-12-57-20.csv\n"
     ]
    }
   ],
   "source": [
    "# 'CMC_id' is the key to both dataframes, however 'repo', and 'forge' are duplicated\n",
    "dfm = pd.merge(dfs, df, on = ['CMC_id','repo','forge'], how = 'outer')\n",
    "\n",
    "# write SQL query update to clickhouse_queries.csv\n",
    "dfm.to_csv('clickhouse_queries.csv', encoding='utf-8')\n",
    "\n",
    "# timestamp\n",
    "date_time = datetime.fromtimestamp(time.time())\n",
    "# convert timestamp to string in dd-mm-yyyy HH:MM:SS\n",
    "str_date_time = date_time.strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "str_filename = 'clickhouse_queries_updated_' + str_date_time + '.csv'\n",
    "\n",
    "# make a backup of clickhouse_queries.csv\n",
    "dfm.to_csv(str_filename, encoding='utf-8')\n",
    "\n",
    "print('Data written to: '+str_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health-env",
   "language": "python",
   "name": "health-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
